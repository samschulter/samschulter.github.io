<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title></title>
<!-- 2017-06-27 Tue 19:50 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Samuel Schulter" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="css/main.css" type="text/css" media="screen" />
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title"></h1>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Samuel Schulter</h2>
<div class="outline-text-2" id="text-1">
<p>
I'm a researcher in the <a href="http://www.nec-labs.com/research-departments/media-analytics/media-analytics-home">Media-Analytics Department at NEC-Labs America</a> in Cupertino, CA.
My research interests are in computer vision and machine learning. I'm currently working on object detection and tracking in videos and higher-level 3D scene understanding.
I received my PhD in 2015 from Graz University of Technology under the supervision of <a href="https://www.tugraz.at/institute/icg/research/team-bischof/people/team-about/horst-bischof/">Horst Bischof</a>.
</p>

<p>
Email: samuel &lt;at&gt; nec-labs &lt;dot&gt; com
</p>

<p>
<a href="https://scholar.google.com/citations?user=VQ6dsFEAAAAJ">Google Scholar</a>
</p>
</div>
</div>


<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Publications</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li><b>Deep Network Flow for Multi-Object Tracking</b>. S. Schulter, P. Vernaza, W. Choi, M. Chandraker. CVPR 2017. <a href="http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/cvpr17_deepnetworkflow.pdf">(PDF</a>, <a href="http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/cvpr17_deepnetworkflow_supp.pdf">SUPP</a>)
</li>
<li><b>Loss-Specific Training of Random Forests for Super-Resolution</b>. A. Grabner, G. Poier, M. Opitz, S. Schulter, P. M. Roth. Computer Vision Winter Workshop 2017. (<a href="http://cvww2017.prip.tuwien.ac.at/papers/CVWW2017_paper_23.pdf">PDF</a>)
</li>

<li><b>Interactive 3D Segmentation of Rock-Art by Enhanced Depth Maps and Gradient Preserving Regularization</b>. M. Zeppelzauer, G. Poier, M. Seidl, C. Reinbacher, S. Schulter, C. Breiteneder, H. Bischof. ACM Journal on Computing and Cultural Heritage 9 (4): 19:1-19:30, 2016 (<a href="http://dx.doi.org/10.1145/2950062">PDF</a>)
</li>
<li><b>Conditioned Regression Models for Non-Blind Single Image Super-Resolution</b>. G. Riegler, S. Schulter, M. Ruether, H. Bischof. ICCV 2015. (<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Riegler_Conditioned_Regression_Models_ICCV_2015_paper.pdf">PDF</a>)
</li>
<li><b>Hybrid One-Shot 3D Hand Pose Estimation by Exploiting Uncertainties</b>. G. Poier, K. Roditakis, S. Schulter, D. Michel, H. Bischof A. A. Argyros. BMVC 2015. (<a href="https://files.icg.tugraz.at/f/0675245487/?raw=1">PDF</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/hybridhpe">PROJECT</a>)
</li>
<li><b>Interactive Segmentation of Rock-Art in High-Resolution 3D Reconstructions</b>. M. Zeppelzauer, G. Poier, M. Seidl, C. Reinbacher, C. Breiteneder, H. Bischof, S. Schulter. Digital Heritage Conference 2015. (<a href="http://ieeexplore.ieee.org/document/7419450/">PDF</a>)
</li>
<li><b>You Should Use Regression to Detect Cells</b>. P. Kainz, M. Urschler, S. Schulter, P. Wohlhart, V. Lepetit. MICCAI 2015. (<a href="https://link.springer.com/chapter/10.1007/978-3-319-24574-4_33">PDF</a>, <a href="https://github.com/pkainz/MICCAI2015">CODE</a>)
</li>
<li><b>Fast and Accurate Super Resolution with Random Forests</b>. S. Schulter, C. Leistner, H. Bischof. CVPR 2015. (<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schulter_Fast_and_Accurate_2015_CVPR_paper.pdf">PDF</a>, <a href="http://lrs.icg.tugraz.at/pubs/schulter_cvpr_2015_supp.pdf">SUPP</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/learning-recognition-surveillance/downloads/forests/#srf">CODE</a>)
</li>

<li><b>Hough Forests Revisited: An Approach to Multiple Instance Tracking from Multiple Cameras</b>. G. Poier, S. Schulter, S. Sternig, P. M. Roth, H. Bischof. GCPR 2014. (<a href="https://link.springer.com/chapter/10.1007/978-3-319-11752-2_41">PDF</a>)
</li>
<li><b>Accurate Object Detection with Joint Classification-Regression Random Forests</b>. S. Schulter, C. Leistner, P. Wohlhart, P. M. Roth, H. Bischof. CVPR 2014. (<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Schulter_Accurate_Object_Detection_2014_CVPR_paper.pdf">PDF</a>)
</li>

<li><b>Alternating Regression Forests for Object Detection and Pose Estimation</b>. S. Schulter, C. Leistner, P. Wohlhart, P. M. Roth, H. Bischof. ICCV 2013. (<a href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Schulter_Alternating_Regression_Forests_2013_ICCV_paper.pdf">PDF</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/forests#adf">CODE</a>)
</li>
<li><b>Unsupervised Object Discovery and Segmentation in Videos</b>. S. Schulter, C. Leistner, P. M. Roth, H. Bischof. BMVC 2013. (<a href="http://www.bmva.org/bmvc/2013/Papers/paper0053/">PDF</a>)
</li>
<li><b>Ordinal Random Forests for Object Detection</b>. S. Schulter, P. M. Roth, H. Bischof. GCPR 2013. (<a href="https://link.springer.com/chapter/10.1007/978-3-642-40602-7_29">PDF</a>)
</li>
<li><b>Alternating Decision Forests</b>. S. Schulter, P. Wohlhart, C. Leistner, A. Saffari, P. M. Roth, H. Bischof. CVPR 2013. (<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Schulter_Alternating_Decision_Forests_2013_CVPR_paper.pdf">PDF</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/forests#adf">CODE</a>)
</li>

<li><b>Discriminative Hough Forests for Object Detection</b>. P. Wohlhart, S. Schulter, M. Koestinger, P. M. Roth, H. Bischof. BMVC 2012. (<a href="http://www.bmva.org/bmvc/2012/BMVC/paper040/">PDF</a>)
</li>

<li><b>Improving Classifiers with Unlabeled Weakly-Related Videos</b>. C. Leistner, M. Godec, S. Schulter, A. Saffari, M. Werlberger, H. Bischof. CVPR 2011. (<a href="http://ieeexplore.ieee.org/document/5995475/?reload=true&arnumber=5995475">PDF</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/forests#vhf">CODE</a>)
</li>
<li><b>On-line Hough Forests</b>. S. Schulter, C. Leistner, P. M. Roth, L. Van Gool, H. Bischof. BMVC 2011. (<a href="http://www.bmva.org/bmvc/2011/proceedings/paper128/paper128.pdf">PDF</a>, <a href="https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/forests#ohf">CODE</a>)
</li>
</ul>
</div>
</div>
</div>
</body>
</html>
